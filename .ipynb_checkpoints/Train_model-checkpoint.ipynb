{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997b958f-3a2c-483f-b62d-24c7e999e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, cv2, albumentations as A, os, numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c67bd42-43ec-4fd3-aaf2-8568232a0823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ab1cf9-1df8-495d-b4d1-6067e41aec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/e/UCSD/Senior_Year/Senior_Design\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeee5d2-7a46-4fb9-8ed3-3e0146e15933",
   "metadata": {},
   "source": [
    "### Load Data from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90393c7c-d6dc-47a4-86b2-7dc83ec6cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2)\n",
    "])\n",
    "\n",
    "# Function to apply augmentations dynamically\n",
    "def augment_on_the_fly(image, mask):\n",
    "    augmented = augmentation_pipeline(image=image, mask=mask)\n",
    "    return augmented['image'], augmented['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e76a2-bcfb-4388-aaae-754d8924f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional block\n",
    "def conv_block(inputs, filters, kernel_size=(3, 3), activation='relu', padding='same'):\n",
    "    x = Conv2D(filters, kernel_size, activation=activation, padding=padding)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, kernel_size, activation=activation, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# Define an encoder block\n",
    "def encoder_block(inputs, filters):\n",
    "    x = conv_block(inputs, filters)\n",
    "    p = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "# Define a decoder block\n",
    "def decoder_block(inputs, skip_features, filters):\n",
    "    x = Conv2DTranspose(filters, kernel_size=(2, 2), strides=(2, 2), padding='same')(inputs)\n",
    "    x = concatenate([x, skip_features])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "# Define the Multi-Scale U-Net model\n",
    "def multi_scale_unet(input_shape=(256, 256, 3), num_classes=1):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder path\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    # Bridge\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder path\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax')(d4)\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs, outputs, name=\"Multi-Scale-U-Net\")\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (256, 256, 3)  # Replace with the dimensions of your bioimages\n",
    "num_classes = 1  # Use 1 for binary segmentation, or adjust for multi-class segmentation\n",
    "model = multi_scale_unet(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Training example (replace with your dataset)\n",
    "# model.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=50, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669ca7f-42cd-4083-acb4-ea46f9bd5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"image_dataset_1/original/\"\n",
    "mask_dir = \"image_dataset_1/mask\"\n",
    "\n",
    "# Load images\n",
    "train_images = tf.keras.utils.image_dataset_from_directory(\n",
    "    image_dir,\n",
    "    labels=None,  # Set labels to None as this is not classification\n",
    "    image_size=(512, 512),  # Resize images to match model input size\n",
    "    batch_size=32  # Define your batch size\n",
    ")\n",
    "\n",
    "# Load masks\n",
    "train_masks = tf.keras.utils.image_dataset_from_directory(\n",
    "    mask_dir,\n",
    "    labels=None,\n",
    "    image_size=(512, 512),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Normalize images and masks\n",
    "def normalize_img(image):\n",
    "    return tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "train_images = train_images.map(normalize_img)\n",
    "train_masks = train_masks.map(lambda x: tf.expand_dims(tf.cast(x, tf.float32), -1))  # Add channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55159ab0-16c2-4cae-92fe-5e9734b6bd60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
